{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede51bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91a0019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13898 files belonging to 22 classes.\n",
      "Found 1546 files belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "\n",
    "train_data = image_dataset_from_directory(\n",
    "    directory=\"../data/SkinDisease/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224,224),\n",
    "    batch_size=32\n",
    "\n",
    ")\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    directory=\"../data/SkinDisease/test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90678fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing images\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(preprocess)\n",
    "test_data = test_data.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc12705",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data = Sequential([\n",
    "    \n",
    "    keras.layers.RandomFlip('horizontal'),\n",
    "    keras.layers.RandomFlip('vertical'),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "    keras.layers.RandomContrast(0.2),\n",
    "    keras.layers.RandomTranslation(0.2, 0.2),\n",
    "    keras.layers.RandomShear(x_factor=0.05, y_factor=0.05, fill_mode='constant')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e2e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet',include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611272d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "# for layer in base_model.layers[:-20]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e09f6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(224,224,3)))\n",
    "model.add(augment_data)\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(22, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb0f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a87e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 1s/step - accuracy: 0.1568 - loss: 3.4918 - val_accuracy: 0.2891 - val_loss: 2.6681\n",
      "Epoch 2/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 1s/step - accuracy: 0.2349 - loss: 2.9639 - val_accuracy: 0.3234 - val_loss: 2.5268\n",
      "Epoch 3/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 1s/step - accuracy: 0.2810 - loss: 2.7523 - val_accuracy: 0.3512 - val_loss: 2.4305\n",
      "Epoch 4/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 1s/step - accuracy: 0.2985 - loss: 2.6429 - val_accuracy: 0.3797 - val_loss: 2.3705\n",
      "Epoch 5/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 1s/step - accuracy: 0.3160 - loss: 2.5584 - val_accuracy: 0.3790 - val_loss: 2.3309\n",
      "Epoch 6/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 1s/step - accuracy: 0.3299 - loss: 2.5097 - val_accuracy: 0.3913 - val_loss: 2.2973\n",
      "Epoch 7/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 1s/step - accuracy: 0.3462 - loss: 2.4565 - val_accuracy: 0.4023 - val_loss: 2.2714\n",
      "Epoch 8/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 1s/step - accuracy: 0.3604 - loss: 2.4020 - val_accuracy: 0.4088 - val_loss: 2.2406\n",
      "Epoch 9/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 1s/step - accuracy: 0.3644 - loss: 2.3693 - val_accuracy: 0.4049 - val_loss: 2.2223\n",
      "Epoch 10/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 1s/step - accuracy: 0.3803 - loss: 2.3282 - val_accuracy: 0.4120 - val_loss: 2.2103\n",
      "Epoch 11/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 1s/step - accuracy: 0.3764 - loss: 2.3253 - val_accuracy: 0.4185 - val_loss: 2.2007\n",
      "Epoch 12/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 1s/step - accuracy: 0.3870 - loss: 2.2916 - val_accuracy: 0.4256 - val_loss: 2.1713\n",
      "Epoch 13/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 1s/step - accuracy: 0.3942 - loss: 2.2630 - val_accuracy: 0.4327 - val_loss: 2.1669\n",
      "Epoch 14/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 1s/step - accuracy: 0.4019 - loss: 2.2539 - val_accuracy: 0.4308 - val_loss: 2.1567\n",
      "Epoch 15/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 1s/step - accuracy: 0.4048 - loss: 2.2364 - val_accuracy: 0.4308 - val_loss: 2.1587\n",
      "Epoch 16/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 1s/step - accuracy: 0.4093 - loss: 2.2267 - val_accuracy: 0.4347 - val_loss: 2.1412\n",
      "Epoch 17/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 1s/step - accuracy: 0.4076 - loss: 2.2078 - val_accuracy: 0.4398 - val_loss: 2.1311\n",
      "Epoch 18/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 1s/step - accuracy: 0.4209 - loss: 2.1915 - val_accuracy: 0.4379 - val_loss: 2.1279\n",
      "Epoch 19/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 1s/step - accuracy: 0.4211 - loss: 2.1896 - val_accuracy: 0.4373 - val_loss: 2.1209\n",
      "Epoch 20/20\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 1s/step - accuracy: 0.4316 - loss: 2.1746 - val_accuracy: 0.4386 - val_loss: 2.1122\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=20, validation_data=test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
